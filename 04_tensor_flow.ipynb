{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 머신러닝은 소프트웨어다\n",
    "# Explicit Programming 명시적 프로그래밍(일반적으로 짤수 있는 프로그래밍을 지칭)\n",
    "# 머신러닝(스팸메일 판단, 자율주행차,명시적프로그래밍으로 해결할 수 없는일)\n",
    "# 1959 Arthur Samuel \n",
    "# 프로그램 자체가 데이터를 기반으로 학습을 통해 배우는 능력을 가지는 프로그래밍\n",
    "\n",
    "\n",
    "# 지도학습과 비지도학습\n",
    "\n",
    "# 지도학습\n",
    "# Supervised Learning : 데이터에 이름을 하나붙여줌(lable)을 학습\n",
    "# Predictive Model > Duck\n",
    "# Linear Regression(선형)\n",
    "# 라벨의 범위가 상대적으로 넓다(lable의 range)\n",
    "# 1 > 5, 2 > 15, 5 > 68, 8 > 80, 10 > 95 \n",
    "\n",
    "# Logistic Regression(Binary Class)\n",
    "# 라벨이 2개 중 한개\n",
    "# 1 > F, 2 > F, 5 > F, 8 > T, 10 > T\n",
    "\n",
    "# Multinomial Classification(Multi-label Classification)\n",
    "# 라벨이 N개 중 한개\n",
    "# 1 > F, 2 > F, 5 > D, 8 > B, 10 >  A\n",
    "\n",
    "\n",
    "# 비지도학습\n",
    "# Unsupervised Learning : 데이터에 이름(lable)이 없고 데이터만 들어옴, 새로운 그룹같은경우 데이터를 이용해 스스로 학습\n",
    "\n",
    "\n",
    "# 데이터를 가정함 Linear인가? Logistic 인가? Multinomial 인가?\n",
    "# 가설\n",
    "# Linear Hypothesis : 선을 수정하며 데이터에 가장 적합한 선을 찾는과정\n",
    "# H(x) = W(weight)x + b < Hypothesis(가설) W와 b를 찾겠다 > 가설의 완성\n",
    "# Cost(Loss) Function 사용\n",
    "# 가설과 실제데이터의차이가 적으면 적을수록 좋은 가설이다.\n",
    "# Cost(Loss) Function : 가설과 training data간의 값의 차를 계산하는 함수\n",
    "# cost값을 최소화하는 경로와\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tensorflow는 data flow graph를 이용해서 수학적 연산을 하는\n",
    "# 구글에서 만든 maching learning 을 위한 one source livarary\n",
    "# 그래프를 만들어요(node라는 개념과 edge라는 개념이 있어요)\n",
    "# node가 하는일은 수학적 연산(사칙연산)과 현재 node가 가지고있는 tensor를 출력\n",
    "# tensor : 동적형태의 다차원 매트릭스를  tensor라고 함 행열\n",
    "# edge tensor를 node로 실어 나르는 역할\n",
    "# tensorflow에서 사용하는 graph는 방향성이 있는 graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=string)\n",
      "b'Hello World'\n"
     ]
    }
   ],
   "source": [
    "node1 = tf.constant(\"Hello World\")\n",
    "print(node1)\n",
    "# graph를 실행시켜주는 runner의 역할을 하는 session을 생성\n",
    "sess = tf.Session()\n",
    "\n",
    "print(sess.run(node1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node3 : 40.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "node1 = tf.constant(10, dtype=tf.float64)\n",
    "node2 = tf.constant(30, dtype=tf.float64)\n",
    "\n",
    "node3 = node1 + node2 # node3 = tf.add(node1, node2)\n",
    "sess = tf.Session()\n",
    "print(\"node3 : {0}\".format(sess.run(node3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node3 :80.0\n"
     ]
    }
   ],
   "source": [
    "# 입력 parameter를 사용해 보아요!!\n",
    "node1 = tf.placeholder(dtype=tf.float64) #  입력파라메타를 받아드릴 수 있는 공간, 무엇인가를 간직한다\n",
    "node2 = tf.placeholder(dtype=tf.float64)\n",
    "node3 = node1 + node2\n",
    "sess = tf.Session()\n",
    "print(\"node3 :{0}\".format(sess.run(node3, feed_dict={node1:30, node2:50}))) # 먹이를 줄건데 dict로 줄거다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-1.4793555] b: [-1.071534] cost:40.46199035644531\n",
      "W: [0.99657345] b: [0.00778932] cost:8.704106221557595e-06\n",
      "W: [0.9983354] b: [0.00378387] cost:2.0538748231047066e-06\n",
      "W: [0.99919134] b: [0.00183831] cost:4.847795480600325e-07\n",
      "W: [0.99960685] b: [0.00089347] cost:1.1454523018983309e-07\n",
      "W: [0.9998088] b: [0.00043466] cost:2.710087620982904e-08\n",
      "W: [0.99990684] b: [0.00021182] cost:6.434888177864195e-09\n",
      "W: [0.9999545] b: [0.00010349] cost:1.5375244410975597e-09\n",
      "W: [0.9999776] b: [5.0984014e-05] cost:3.7327177460078076e-10\n",
      "W: [0.9999892] b: [2.4329604e-05] cost:8.619357311223652e-11\n",
      "W: [0.9999942] b: [1.2732944e-05] cost:2.3987922759260982e-11\n"
     ]
    }
   ],
   "source": [
    "# 기본적인 linear regression에 대한 tensorflow code\n",
    "import tensorflow as tf\n",
    "# training data set\n",
    "x = [1, 2, 3]\n",
    "y = [1, 2, 3]\n",
    "\n",
    "# weight & bias (training variable 선언)\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\") # w정의 변하는 랜덤값 1개 이름은 weight\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "H = W * x + b # 이 H를 구하는게 우리의 최종 목표(W와 b값을 구하는게 우리의 목표)\n",
    "# 최적의 가설을 만들기 위해 Cost(Loss) function을 이용\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(H-y)) # H에서 y값을 뺀 제곱의 평균을 구함\n",
    "\n",
    "# cost function을 최소화 시키는 작업을 진행\n",
    "# 최소화 시키는 작업은 한방에 되지않아요!\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01) # 학습률은 얼마만큼 이동할거냐를 정함\n",
    "train = optimizer.minimize(cost) # cost값을 반복적으로 줄여줌\n",
    "\n",
    "# run\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(3001):\n",
    "    sess.run(train)\n",
    "    if step % 300 == 0:\n",
    "        print(\"W: {0}\".format(sess.run(W)), end=\" \") # 1로 점점점옴\n",
    "        print(\"b: {0} cost:{1}\".format(sess.run(b), sess.run(cost)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [0.9459386] b: [-0.960993] cost: 21.825571060180664\n",
      "W: [2.2680767] b: [0.39059907] cost: 0.05353233218193054\n",
      "W: [2.1302202] b: [0.7039795] cost: 0.012631452642381191\n",
      "W: [2.0632553] b: [0.85620576] cost: 0.002980516292154789\n",
      "W: [2.0307262] b: [0.93015176] cost: 0.0007032709545455873\n",
      "W: [2.0149255] b: [0.9660705] cost: 0.00016594736371189356\n",
      "W: [2.0072503] b: [0.9835184] cost: 3.91551002394408e-05\n",
      "W: [2.003522] b: [0.99199355] cost: 9.240164217771962e-06\n",
      "W: [2.001712] b: [0.9961087] cost: 2.182679054385517e-06\n",
      "W: [2.000833] b: [0.99810696] cost: 5.167273116057913e-07\n",
      "W: [2.0004067] b: [0.99907744] cost: 1.228164450139957e-07\n",
      "예측값 : [61.01128]\n"
     ]
    }
   ],
   "source": [
    "# x, y 를 변수로\n",
    "# 기본적인 linear regression에 대한 tensorflow code\n",
    "import tensorflow as tf\n",
    "# training data set\n",
    "# x = [1, 2, 3]\n",
    "# y = [1, 2, 3]\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "# weight & bias (training variable 선언)\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\") # w정의 변하는 랜덤값 1개 이름은 weight\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\") # variable을 만들땐 꼭 초기화 시켜줘야함\n",
    "\n",
    "H = W * x + b # 이 H를 구하는게 우리의 최종 목표(W와 b값을 구하는게 우리의 목표)\n",
    "# 최적의 가설을 만들기 위해 Cost(Loss) function을 이용\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(H-y)) # H에서 y값을 뺀 제곱의 평균을 구함 cost는 정해져 있음\n",
    "\n",
    "# cost function을 최소화 시키는 작업을 진행\n",
    "# 최소화 시키는 작업은 한방에 되지않아요!\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01) # 학습률은 얼마만큼 이동할거냐를 정함\n",
    "train = optimizer.minimize(cost) # cost값을 반복적으로 줄여줌\n",
    "\n",
    "# run\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(3001):\n",
    "    _, w_val, b_val, cost_val = sess.run([train, W, b, cost], feed_dict={x:[1,2,3], y:[3,5,7]}) # _ : 변수를 사용하지 않는다\n",
    "    if step % 300 == 0:\n",
    "        print(\"W: {0} b: {1} cost: {2}\".format(w_val, b_val, cost_val)) # 1로 점점점옴\n",
    "\n",
    "\n",
    "# prediction\n",
    "print(\"예측값 : {0}\".format(sess.run(H, feed_dict={x: [30]}))) # x가 30일때 y의 예측값\n",
    "\n",
    "# 행렬매트릭스를 사용할경우 H(X) = XW X를 앞에 위치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost(Loss) function의 심화\n",
    "#  w에 기울기 * a(learning_rate 를조절해서) 값을 빼면서 기울기가 0이될때까지 진행함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과 예측값 : [[185.52934]]\n"
     ]
    }
   ],
   "source": [
    "# 다중입력을 위한 linear regression\n",
    "import tensorflow as tf\n",
    "# training data set\n",
    "# matrix로 표현\n",
    "x_data = [[73, 80, 75],\n",
    "          [93, 88, 93],\n",
    "          [89, 91, 90],\n",
    "          [96, 98, 100],\n",
    "          [73, 76, 70]\n",
    "         ]\n",
    "\n",
    "y_data = [[152],\n",
    "          [185],\n",
    "          [180],\n",
    "          [196],\n",
    "          [142]\n",
    "         ]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None , 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None , 1])\n",
    "# None은 상관하지않겠다. 근데 열은 3열이다.\n",
    "# 매트릭스에는 입력값의 형태를 반드시 지정해줘야한다. \n",
    "W = tf.Variable(tf.random_normal([3, 1]))\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# hypothesis(가설)\n",
    "H = tf.matmul(X, W) + b # 순서 주의 X먼저\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.square(H-Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "# session 생성 및 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) # 초기화를 무조건 한다음에 실행을해야 됨\n",
    "\n",
    "# 학습진행\n",
    "for step in range(3000):\n",
    "    sess.run(train, feed_dict={X:x_data, Y: y_data})\n",
    "\n",
    "print(\"결과 예측값 : {0}\".format(sess.run(H, feed_dict={X:[[100, 100, 50]]})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression 둘중 하나의값으로 떨어질때\n",
    "# Linear 로 표시하려면 범위값이 넓어질경우 오류값을 도출 할 수 있음\n",
    "# 결과값이 0과 1사이의 값으로 바인딩 되어야 한다.\n",
    "# Linear인지 Logistic인지에따라 가설과 cost가 달라진다.\n",
    "# cost함수는 굴곡이있다. 지수승이기 때문 미분을해서 최소값을 찾는다는 보장이없다. 코스트함수를 바꾸자!!\n",
    "# 로그를 취하면 굴곡이 없어지겠네!\n",
    "# logistic부터는 정확도가 들어감. 이 학습은 ㅇㅇ%의 정확도를 가진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 1.4839518070220947\n",
      "Cost: 1.3289862871170044\n",
      "Cost: 1.1899559497833252\n",
      "Cost: 1.0690137147903442\n",
      "Cost: 0.9671557545661926\n",
      "Cost: 0.8839806914329529\n",
      "Cost: 0.8177627325057983\n",
      "Cost: 0.7658487558364868\n",
      "Cost: 0.7252693176269531\n",
      "Cost: 0.6932743191719055\n",
      "Cost: 0.6676095128059387\n",
      "Cost: 0.6465619206428528\n",
      "Cost: 0.6288847923278809\n",
      "Cost: 0.6136903166770935\n",
      "Cost: 0.6003506779670715\n",
      "Cost: 0.5884217023849487\n",
      "Cost: 0.5775865316390991\n",
      "Cost: 0.5676173567771912\n",
      "Cost: 0.5583478212356567\n",
      "Cost: 0.549655556678772\n",
      "Cost: 0.541448712348938\n",
      "Cost: 0.5336576104164124\n",
      "Cost: 0.5262289047241211\n",
      "Cost: 0.5191206336021423\n",
      "Cost: 0.512299656867981\n",
      "Cost: 0.5057393908500671\n",
      "Cost: 0.49941807985305786\n",
      "Cost: 0.4933176338672638\n",
      "Cost: 0.4874228835105896\n",
      "Cost: 0.4817211329936981\n",
      "Cost: 0.4762008488178253\n",
      "Cost: 0.4708525240421295\n",
      "Cost: 0.4656673073768616\n",
      "Cost: 0.46063750982284546\n",
      "Cost: 0.4557560384273529\n",
      "Cost: 0.45101651549339294\n",
      "Cost: 0.4464128911495209\n",
      "Cost: 0.4419398605823517\n",
      "Cost: 0.43759211897850037\n",
      "Cost: 0.43336495757102966\n",
      "Cost: 0.42925378680229187\n",
      "Cost: 0.42525437474250793\n",
      "Cost: 0.42136260867118835\n",
      "Cost: 0.41757461428642273\n",
      "Cost: 0.41388678550720215\n",
      "Cost: 0.4102955162525177\n",
      "Cost: 0.40679749846458435\n",
      "Cost: 0.4033895432949066\n",
      "Cost: 0.4000685513019562\n",
      "Cost: 0.39683154225349426\n",
      "정확도 :0.8571428656578064\n",
      "예측값은 : [[1.]]\n"
     ]
    }
   ],
   "source": [
    "# tensorflow module 불러오기\n",
    "import tensorflow as tf\n",
    "\n",
    "# Training Data set 불러오기\n",
    "x_data = [[10, 0],\n",
    "          [8, 1],\n",
    "          [3, 3],\n",
    "          [2, 3],\n",
    "          [5, 1],\n",
    "          [2, 0],\n",
    "          [1, 0]\n",
    "         ]\n",
    "y_data = [[1], [1], [1], [1], [0], [0], [0]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 2]) # 되도록 float32쓰는게 좋다\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "# 가설은 W, b로 구성할 수 있다.\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "H = tf.sigmoid(tf.matmul(X,W) + b) # 곡선으로 그림\n",
    "\n",
    "# cost function\n",
    "cost = -tf.reduce_mean(Y * tf.log(H)+(1-Y)*tf.log(1-H))\n",
    "\n",
    "# train node를 생성\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "# session & initialization\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(15000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict = {X: x_data, Y : y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(\"Cost: {0}\".format(cost_val))\n",
    "\n",
    "# 학습이 끝나면 정확도 측정을 해야함\n",
    "\n",
    "# tf.cast() => 실수형에서 정수형으로 바꾼경우는 소수점을 잘라낸다.\n",
    "#              Boolean이 cast의 인자로 들어오는 경우 true면 1, False면 0으로 cast\n",
    "predict = tf.cast(H > 0.5, dtype=tf.float32) # 0혹은 1값으로 떨어짐\n",
    "correct = tf.equal(predict, Y) # 실데이터와 우리프로그램의 예측값이 같은지를 비교\n",
    "                                # 당연히 같아야 좋은거다!\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(\"정확도 :{0}\".format(sess.run(accuracy, feed_dict={X:x_data, Y:y_data})))\n",
    "print(\"예측값은 : {0}\".format(sess.run(predict, feed_dict={X:[[3, 5]]}))) # 3시간공부하고 체류시간이 5년이넘은놈은 예측하면 1\n",
    "# 0과 1의 경계를 찾는것이  logistic(hyperplane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "logits and labels must be broadcastable: logits_size=[6,3] labels_size=[14000,3]\n\t [[node softmax_cross_entropy_with_logits (defined at <ipython-input-13-c3fe00911b75>:35)  = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Softmax_9, softmax_cross_entropy_with_logits/Reshape_1)]]\n\nCaused by op 'softmax_cross_entropy_with_logits', defined at:\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-c3fe00911b75>\", line 35, in <module>\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=H,  labels=train_y_data))\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1864, in softmax_cross_entropy_with_logits_v2\n    precise_logits, labels, name=name)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 7747, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): logits and labels must be broadcastable: logits_size=[6,3] labels_size=[14000,3]\n\t [[node softmax_cross_entropy_with_logits (defined at <ipython-input-13-c3fe00911b75>:35)  = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Softmax_9, softmax_cross_entropy_with_logits/Reshape_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: logits and labels must be broadcastable: logits_size=[6,3] labels_size=[14000,3]\n\t [[{{node softmax_cross_entropy_with_logits}} = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Softmax_9, softmax_cross_entropy_with_logits/Reshape_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c3fe00911b75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m300\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cost : {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: logits and labels must be broadcastable: logits_size=[6,3] labels_size=[14000,3]\n\t [[node softmax_cross_entropy_with_logits (defined at <ipython-input-13-c3fe00911b75>:35)  = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Softmax_9, softmax_cross_entropy_with_logits/Reshape_1)]]\n\nCaused by op 'softmax_cross_entropy_with_logits', defined at:\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-c3fe00911b75>\", line 35, in <module>\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=H,  labels=train_y_data))\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1864, in softmax_cross_entropy_with_logits_v2\n    precise_logits, labels, name=name)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 7747, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\SDEDU03\\AppData\\Local\\Continuum\\anaconda3\\envs\\jctensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): logits and labels must be broadcastable: logits_size=[6,3] labels_size=[14000,3]\n\t [[node softmax_cross_entropy_with_logits (defined at <ipython-input-13-c3fe00911b75>:35)  = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Softmax_9, softmax_cross_entropy_with_logits/Reshape_1)]]\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Classification\n",
    "# 선이 여러개 A가 될수있을확률, B가될수 있을확률, C가될수있는 확률이 나온다\n",
    "import tensorflow as tf\n",
    "\n",
    "#training\n",
    "x_data =[[10, 7, 8, 5],\n",
    "        [8,8,9,4],\n",
    "         [6,3,9,3],\n",
    "         [7,5,7,4],\n",
    "         [3,5,6,2],\n",
    "         [2,4,3,1]\n",
    "        ]\n",
    "# H => [[0.7, 0.2, 0.1]] 확률값 다더하면 1로 출력됨 => softmax\n",
    "\n",
    "y_data = [[1, 0, 0], # 원핫 one_hot encoding 인코딩 \"A\"\n",
    "          [1, 0, 0],\n",
    "          [0, 1, 0], # \"B\"\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 0, 1], # \"C\"\n",
    "          [0, 0, 1],\n",
    "         ]\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, 3])\n",
    "W = tf.Variable(tf.random_normal([4, 3]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "# Linear : H = tf.matmul(X, W) + b\\\n",
    "# Logistic : tf.sigmod(tf.matmul(X,W) + b)\n",
    "# Multinomial : tf.nn.softmax(tf.matmul(X, W)+b)\n",
    "H = tf.nn.softmax(tf.matmul(X,W) + b)\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(H), axis=1))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data, Y: y_data})\n",
    "    if step % 300 ==0:\n",
    "        print(\"Cost : {0}\".format(cost_val))\n",
    "\n",
    "#prediction\n",
    "result = sess.run(H, feed_dict={X:[[10, 9, 5, 1]]})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 10.752534866333008\n",
      "Cost: 0.6702790260314941\n",
      "Cost: 0.3743709921836853\n",
      "Cost: 0.2927321791648865\n",
      "Cost: 0.24879901111125946\n",
      "Cost: 0.21948029100894928\n",
      "Cost: 0.19776317477226257\n",
      "Cost: 0.18065941333770752\n",
      "Cost: 0.16664056479930878\n",
      "Cost: 0.15482810139656067\n",
      "Cost: 0.14467307925224304\n",
      "[[9.9998248e-01 3.7470363e-06 1.3783676e-05]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial\n",
    "import tensorflow as tf\n",
    "\n",
    "# Training Set\n",
    "x_data = [[10, 7, 8, 5],\n",
    "          [8, 8, 9, 4],\n",
    "          [7, 3, 2, 3],\n",
    "          [6, 3, 9, 3],\n",
    "          [7, 5, 7, 4],\n",
    "          [3, 5, 6, 2],\n",
    "          [2, 4, 3, 1]\n",
    "         ]\n",
    "\n",
    "# One - hot Encoding\n",
    "y_data = [[1, 0, 0], # \"A\"\n",
    "          [1, 0, 0],\n",
    "          [0, 1, 0], # \"B\"\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 0, 1], # \"C\"\n",
    "          [0, 0, 1]\n",
    "         ]\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, 3]) # Logistic * 3\n",
    "\n",
    "# Variable\n",
    "W = tf.Variable(tf.random_normal([4, 3]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "H = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cost\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(H), axis=1))\n",
    "\n",
    "# Train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(3001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(\"Cost: {0}\".format(cost_val))\n",
    "        \n",
    "# prediction\n",
    "result = sess.run(H, feed_dict={X:[[10,9,5,1]]})\n",
    "\n",
    "print (result)\n",
    "\n",
    "argmax = tf.argmax(result, axis=1) # 안에들어온것에서 최댓값 찾기 행? 열? 가장큰값의 인덱스 리턴\n",
    "sess.run(argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 3.787554979324341\n",
      "Cost: 0.3727300763130188\n",
      "Cost: 0.22338570654392242\n",
      "Cost: 0.15394410490989685\n",
      "Cost: 0.11283519119024277\n",
      "Cost: 0.08670740574598312\n",
      "Cost: 0.06965148448944092\n",
      "Cost: 0.05802008509635925\n",
      "Cost: 0.04969168081879616\n",
      "Cost: 0.04347260296344757\n",
      "Cost: 0.03866628557443619\n",
      "[[7.2992909e-05 7.1902876e-04 4.9209408e-04 2.8796507e-09 2.4894013e-03\n",
      "  9.8916924e-01 7.0572631e-03]]\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "# Practice1\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Data load\n",
    "data = np.loadtxt(\"data/zoo/zoo.csv\", delimiter=\",\")\n",
    "\n",
    "# Separated X, Y Data from data\n",
    "x_data = data[:,:-1]\n",
    "y_data = data[:,-1:]\n",
    "\n",
    "# Feature Size = 16\n",
    "feature_size = x_data.shape[1]\n",
    "\n",
    "# Category Size = 7\n",
    "category_size = len(np.unique(y_data.ravel()))\n",
    "\n",
    "# Y One-hot encoding\n",
    "y_data = tf.one_hot(y_data, category_size)\n",
    "\n",
    "# Convert Tensor object to ndarray\n",
    "sess = tf.Session()\n",
    "y_data = sess.run(tf.reshape(y_data, shape=[-1, category_size]))\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, feature_size])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, category_size])\n",
    "\n",
    "# Variable\n",
    "W = tf.Variable(tf.random_normal([feature_size, category_size]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([category_size]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "H = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cost\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(H), axis=1))\n",
    "\n",
    "# Train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(30001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 3000 == 0:\n",
    "        print(\"Cost: {0}\".format(cost_val))\n",
    "\n",
    "result = sess.run(H, feed_dict={X:[[0,0,1,0,1,0,0,0,0,1,0,0,6,0,0,0]]})\n",
    "print(result)\n",
    "\n",
    "argmax = tf.argmax(result, axis=1)\n",
    "print(sess.run(argmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1., 188.,  71.],\n",
       "       [  2., 161.,  68.],\n",
       "       [  0., 178.,  52.],\n",
       "       ...,\n",
       "       [  1., 150.,  48.],\n",
       "       [  1., 189.,  69.],\n",
       "       [  1., 142.,  41.]], dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deep learning BMI예제\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# data loading\n",
    "input = np.loadtxt(\"data/bmi/bmi.csv\", delimiter=\",\", dtype=np.float32)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: 7.921048641204834\n",
      "cost: 0.10015028715133667\n",
      "cost: 0.07326173037290573\n",
      "cost: 0.0630616545677185\n",
      "cost: 0.05651768296957016\n",
      "cost: 0.052390772849321365\n",
      "cost: 0.04933043569326401\n",
      "cost: 0.04693260043859482\n",
      "cost: 0.04493483155965805\n",
      "cost: 0.04322007670998573\n",
      "정확도 : 0.9944999814033508\n"
     ]
    }
   ],
   "source": [
    "# deep learning BMI예제\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# data loading\n",
    "input = np.loadtxt(\"data/bmi/bmi.csv\", delimiter=\",\", dtype=np.float32)\n",
    "input\n",
    "\n",
    "# traing data set\n",
    "# 일반적으로 전체 데이터의 70%를 학습데이터로 이용하고\n",
    "# 30% 를 테스트 용도로 사용합니다.\n",
    "\n",
    "num_of_train = int(len(input) * 0.7) # 0.7만 학습데이터로 사용\n",
    "\n",
    "\n",
    "\n",
    "train_x_data = input[:num_of_train, 1:]\n",
    "train_y_data = input[:num_of_train, [0]]\n",
    "\n",
    "test_x_data = input[num_of_train:, 1:]\n",
    "test_y_data = input[num_of_train:, [0]]\n",
    "# Normalization ( scailing ) : X데이터를 0과 1사이의 값으로 변환\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "train_x_data = scaler.fit_transform(train_x_data)\n",
    "test_x_data = scaler.fit_transform(test_x_data)\n",
    "train_y_data\n",
    "\n",
    "# multinomial이기 때문에 y쪽 lable을 one-hot encoding으로 변환\n",
    "train_y_data = tf.one_hot(train_y_data, 3)\n",
    "train_y_data = tf.reshape(train_y_data,[-1,3])\n",
    "test_y_data = tf.one_hot(test_y_data, 3)\n",
    "test_y_data = tf.reshape(test_y_data,[-1, 3])\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(train_y_data)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, 2])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, 3])\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([2, 3]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]), name=\"bias\")\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 10]), name=\"weight1\")\n",
    "b1 = tf.Variable(tf.random_normal([10]), name=\"bias1\")\n",
    "layer1 = tf.nn.relu(tf.matmul(X, W1) + b1) # softmax보다 효율이 좋은 relu 첫번째 축으로 세움 수많은 레이어들을 이용해 내가원하는 가설을 생성\n",
    "\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([10, 50]), name=\"weight2\")\n",
    "b2 = tf.Variable(tf.random_normal([50]), name=\"bias2\")\n",
    "layer2 = tf.nn.relu(tf.matmul(layer1, W2) + b2) # softmax보다 효율이 좋은 relu 첫번째 축으로 세움\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([60, 3]), name=\"weight3\")\n",
    "b3 = tf.Variable(tf.random_normal([3]), name=\"bias3\")\n",
    "H = tf.nn.relu(tf.matmul(layer2, W3) + b3) # softmax보다 효율이 좋은 relu 첫번째 축으로 세움\n",
    "\n",
    "\n",
    "\n",
    "# Hypothesis\n",
    "# H = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=H,  labels=train_y_data)) # 버전 2라는것을 이용해야한다 logits=H을씌워야함\n",
    "\n",
    "# train\n",
    "# train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost) 일은같은데 알고리즘이 다름\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# session 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:train_x_data, Y:sess.run(train_y_data)})\n",
    "    if step % 300 == 0:\n",
    "        print(\"cost: {0}\".format(cost_val))\n",
    "        \n",
    "# 정확도 측정\n",
    "# predict한 결과는 확률(thin일 확률, 정상일 확률, fat일 확률)\n",
    "predict = tf.argmax(H, axis=1) # 열 단위로 가장 큰 값을 찾아 그놈의 인덱스를 알아와요\n",
    "correct = tf.equal(predict, tf.argmax(Y, axis = 1)) # 추정치와 실제 데이터가 같은지를 비교\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype = tf.float32))\n",
    "\n",
    "print(\"정확도 : {0}\".format(sess.run(accuracy, feed_dict = {X:test_x_data, Y:sess.run(test_y_data)})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jctensorflow]",
   "language": "python",
   "name": "conda-env-jctensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
